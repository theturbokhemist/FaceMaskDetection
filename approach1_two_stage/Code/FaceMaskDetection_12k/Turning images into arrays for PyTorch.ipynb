{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88385ec",
   "metadata": {},
   "source": [
    "# Turning images into arrays for PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c001a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95d2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in locations\n",
    "incorrect = r'D:\\data\\face_mask\\FaceMaskDetection_12k\\Cropped\\mask_weared_incorrect' \n",
    "correct = r'D:\\data\\face_mask\\FaceMaskDetection_12k\\Cropped\\with_mask'\n",
    "without = r'D:\\data\\face_mask\\FaceMaskDetection_12k\\Cropped\\without_mask'\n",
    "\n",
    "# out locations\n",
    "output_X_fp =  r'D:\\data\\face_mask\\FaceMaskDetection_12k\\Cropped\\images'\n",
    "output_y_fp =  r'D:\\data\\face_mask\\FaceMaskDetection_12k\\Cropped\\labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09a54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns directory of images into array of images (as pixel vals) and array of labels\n",
    "def image_dir_to_list_of_arrays(input_image_dir, label: int, verbose=False):\n",
    "    \n",
    "    img_array_list = []\n",
    "    for root, subdirectories, files in os.walk(input_image_dir):\n",
    "        for f in files:\n",
    "            \n",
    "            im_fp = os.path.join(input_image_dir, f)\n",
    "            \n",
    "            im = Image.open(im_fp)\n",
    "            im_arr = np.array(im)\n",
    "            \n",
    "            img_array_list.append(im_arr)\n",
    "    \n",
    "    length = len(img_array_list)\n",
    "    \n",
    "    if verbose:\n",
    "        print('{:>5} images'.format(length))\n",
    "    \n",
    "    # list to np array\n",
    "    imgs_as_np_array = np.array(img_array_list)\n",
    "    \n",
    "    # generate labels\n",
    "    label_list = [label] * length\n",
    "    label_array = np.array(label_list).astype(int)\n",
    "    \n",
    "    return imgs_as_np_array, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ee7168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2994 images\n"
     ]
    }
   ],
   "source": [
    "# process correctly worn mask images\n",
    "correct_array, correct_label_array = image_dir_to_list_of_arrays(\n",
    "    correct,\n",
    "    label=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d2aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2994 images\n"
     ]
    }
   ],
   "source": [
    "# process correctly worn mask images\n",
    "incorrect_array, incorrect_label_array = image_dir_to_list_of_arrays(\n",
    "    incorrect,\n",
    "    label=0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcb4933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2994 images\n"
     ]
    }
   ],
   "source": [
    "# process correctly worn mask images\n",
    "without_array, without_label_array = image_dir_to_list_of_arrays(\n",
    "    without,\n",
    "    label=0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "438a82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating arrays\n",
    "FMD_12k_X = np.concatenate([correct_array, incorrect_array, without_array])\n",
    "FMD_12k_y = np.concatenate([correct_label_array, incorrect_label_array, without_label_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf848472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 112, 112, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FMD_12k_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96fddb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FMD_12k_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6518d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving output to file\n",
    "np.save(output_X_fp, FMD_12k_X)\n",
    "np.save(output_y_fp, FMD_12k_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa00ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
